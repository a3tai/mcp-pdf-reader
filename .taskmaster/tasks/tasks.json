{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Go Project Structure and MCP Server Foundation",
        "description": "Initialize the Go project with proper module structure, implement basic MCP server protocol handler, and establish the core architecture for PDF processing",
        "details": "Create Go module with go.mod (require go 1.21+). Implement MCP server following the Model Context Protocol specification:\n\n```go\n// main.go\npackage main\n\nimport (\n    \"github.com/yourusername/mcp-pdf-reader/internal/server\"\n    \"github.com/yourusername/mcp-pdf-reader/internal/pdf\"\n)\n\n// internal/server/mcp.go\ntype MCPServer struct {\n    pdfEngine *pdf.Engine\n    tools     map[string]Tool\n}\n\n// Implement MCP protocol methods: Initialize, ListTools, CallTool\n```\n\nSetup directory structure:\n- /cmd/mcp-pdf-reader/\n- /internal/server/ (MCP protocol handling)\n- /internal/pdf/ (PDF processing engine)\n- /internal/extractors/ (content extractors)\n- /pkg/models/ (data models)\n- /docs/examples/ (test PDFs)\n- /test/",
        "testStrategy": "Unit tests for MCP message handling, integration tests for server startup/shutdown, validate tool registration and basic protocol compliance. Test with mock PDF operations to ensure server responds correctly to MCP requests.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Core PDF Parser with Validation",
        "description": "Build the foundational PDF parsing engine that can read, validate, and parse basic PDF file structure according to PDF 1.4/1.7 specifications",
        "details": "Implement PDF parser using pure Go (no CGO dependencies):\n\n```go\n// internal/pdf/parser.go\ntype PDFParser struct {\n    file     io.ReadSeeker\n    xref     *CrossReferenceTable\n    trailer  map[string]Object\n}\n\nfunc (p *PDFParser) Parse() error {\n    // 1. Read PDF header (%PDF-1.x)\n    // 2. Parse cross-reference table\n    // 3. Read trailer dictionary\n    // 4. Build object catalog\n}\n\n// internal/pdf/validator.go\nfunc ValidatePDF(path string) (*ValidationResult, error) {\n    // Check file signature\n    // Verify xref table\n    // Validate object structure\n}\n```\n\nConsider using pdfcpu (Apache 2.0 license) as a base library or reference implementation. Implement pdf_validate_file MCP tool.",
        "testStrategy": "Test with various PDF versions (1.4, 1.7), corrupted files, and edge cases. Validate against example PDFs in docs/examples/. Ensure proper error handling for malformed PDFs.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Build Content Stream Parser for Text Extraction",
        "description": "Implement PDF content stream parsing to extract basic text content, handling PDF operators and text positioning commands",
        "details": "Parse PDF content streams and implement text extraction:\n\n```go\n// internal/pdf/content_stream.go\ntype ContentStreamParser struct {\n    stream []byte\n    state  GraphicsState\n    text   []ExtractedText\n}\n\n// Handle PDF operators: BT, ET, Tf, Tm, Tj, TJ\nfunc (p *ContentStreamParser) parseOperator(op string, operands []Object) {\n    switch op {\n    case \"BT\": // Begin text\n    case \"Tf\": // Set font\n    case \"Tm\": // Text matrix\n    case \"Tj\": // Show text\n    }\n}\n\n// internal/extractors/text.go\nfunc ExtractText(page *PDFPage) (string, error) {\n    // Parse content stream\n    // Extract text runs\n    // Join into coherent text\n}\n```\n\nImplement pdf_read_file MCP tool for basic text extraction.",
        "testStrategy": "Test text extraction accuracy against known PDFs with various fonts, encodings, and layouts. Compare output with expected text content. Verify handling of special characters and Unicode.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Coordinate System and Positioned Text Extraction",
        "description": "Add coordinate tracking, transformation matrix handling, and positioned text extraction with bounding boxes and formatting information",
        "details": "Enhance text extraction with positioning:\n\n```go\n// internal/pdf/coordinates.go\ntype TransformMatrix [6]float64\n\nfunc (tm TransformMatrix) Transform(x, y float64) (float64, float64) {\n    // Apply transformation matrix\n    return tm[0]*x + tm[2]*y + tm[4], tm[1]*x + tm[3]*y + tm[5]\n}\n\n// pkg/models/text.go\ntype ExtractedText struct {\n    Text   string      `json:\"text\"`\n    Page   int         `json:\"page\"`\n    Bounds BoundingBox `json:\"bounds\"`\n    Font   FontInfo    `json:\"font\"`\n}\n\n// internal/extractors/positioned_text.go\nfunc ExtractStructuredText(page *PDFPage) ([]ExtractedText, error) {\n    // Track current transformation matrix\n    // Calculate absolute positions\n    // Group into words/lines\n    // Preserve font information\n}\n```\n\nImplement pdf_extract_structured MCP tool.",
        "testStrategy": "Validate coordinate accuracy by extracting known positioned elements. Test transformation matrix calculations. Verify bounding boxes align with visual representation.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Develop Line and Paragraph Detection Algorithms",
        "description": "Implement intelligent grouping of positioned text into logical lines and paragraphs based on spatial analysis and proximity",
        "details": "Group text elements into semantic units:\n\n```go\n// internal/extractors/layout.go\ntype LineDetector struct {\n    tolerance float64 // Y-axis tolerance for same line\n}\n\nfunc (ld *LineDetector) GroupIntoLines(texts []ExtractedText) []TextLine {\n    // Sort by Y coordinate (top to bottom)\n    // Group texts with similar Y values\n    // Sort each line by X coordinate\n    // Handle RTL text if needed\n}\n\ntype ParagraphDetector struct {\n    lineSpacing float64\n    indentSize  float64\n}\n\nfunc (pd *ParagraphDetector) GroupIntoParagraphs(lines []TextLine) []Paragraph {\n    // Analyze line spacing\n    // Detect paragraph breaks\n    // Identify indentation patterns\n    // Group related lines\n}\n```\n\nEnhance pdf_extract_structured output with line/paragraph information.",
        "testStrategy": "Test with documents having various layouts: multi-column, mixed fonts, different line spacings. Verify correct paragraph detection and line ordering.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Image and Graphics Extraction",
        "description": "Extract embedded images, vector graphics, and other non-text content with positioning information and metadata",
        "details": "Extract images and graphics from PDF:\n\n```go\n// internal/extractors/images.go\ntype ImageExtractor struct {\n    decoder map[string]ImageDecoder\n}\n\nfunc (ie *ImageExtractor) ExtractImages(page *PDFPage) ([]ExtractedImage, error) {\n    // Find image XObjects\n    // Decode image data (JPEG, PNG, etc.)\n    // Calculate positioning\n    // Extract metadata\n}\n\n// pkg/models/image.go\ntype ExtractedImage struct {\n    Page     int         `json:\"page\"`\n    Bounds   BoundingBox `json:\"bounds\"`\n    Format   string      `json:\"format\"`\n    Data     []byte      `json:\"data,omitempty\"`\n    DataURL  string      `json:\"dataUrl\"`\n    Metadata ImageMeta   `json:\"metadata\"`\n}\n\n// Handle inline images (BI/EI) and XObject images (Do)\n```\n\nImplement pdf_extract_images MCP tool.",
        "testStrategy": "Test with PDFs containing various image formats (JPEG, PNG, TIFF). Verify correct positioning and data extraction. Test inline vs XObject images.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Build Form Field Detection and Extraction",
        "description": "Detect and extract interactive form fields including text fields, checkboxes, radio buttons, and dropdowns with their values and properties",
        "details": "Extract form fields from AcroForms:\n\n```go\n// internal/extractors/forms.go\ntype FormExtractor struct {\n    catalog *PDFCatalog\n}\n\nfunc (fe *FormExtractor) ExtractForms(doc *PDFDocument) ([]FormField, error) {\n    // Get AcroForm dictionary\n    // Parse field tree\n    // Extract field properties\n    // Get current values\n}\n\n// pkg/models/form.go\ntype FormField struct {\n    Name       string      `json:\"name\"`\n    Type       string      `json:\"type\"` // text, checkbox, radio, select\n    Value      interface{} `json:\"value\"`\n    Options    []string    `json:\"options,omitempty\"`\n    Required   bool        `json:\"required\"`\n    Bounds     BoundingBox `json:\"bounds\"`\n    Validation Validation  `json:\"validation,omitempty\"`\n}\n```\n\nImplement pdf_extract_forms MCP tool.",
        "testStrategy": "Test with fillable PDF forms, both empty and filled. Verify field type detection, value extraction, and validation rules. Test nested field hierarchies.",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement AcroForm Dictionary Parser",
            "description": "Create functionality to locate and parse the AcroForm dictionary from the PDF catalog, including handling of field tree structures and inheritance",
            "dependencies": [],
            "details": "Implement methods to: 1) Locate the AcroForm entry in the PDF catalog dictionary, 2) Parse the Fields array to build the field tree hierarchy, 3) Handle field inheritance where child fields inherit properties from parent fields, 4) Extract default appearance settings and form-level properties like NeedAppearances flag",
            "status": "done",
            "testStrategy": "Create unit tests with sample PDF catalog structures containing various AcroForm configurations, including nested field hierarchies and inherited properties"
          },
          {
            "id": 2,
            "title": "Build Field Type Detection and Property Extraction",
            "description": "Implement logic to identify field types (text, checkbox, radio, dropdown) and extract their specific properties including flags, default values, and appearance characteristics",
            "dependencies": [
              1
            ],
            "details": "Create type detection based on FT (Field Type) entry: 1) Tx for text fields, 2) Btn for buttons (checkboxes/radio), 3) Ch for choice fields (dropdowns/lists). Extract field flags to determine multiline, password, file select properties. Parse field dictionaries for properties like MaxLen, default value (DV), current value (V), and field name (T)",
            "status": "done",
            "testStrategy": "Test with PDFs containing each field type, verify correct type identification and property extraction including edge cases like missing optional properties"
          },
          {
            "id": 3,
            "title": "Implement Field Value and Options Extraction",
            "description": "Extract current values from form fields and parse options for choice fields (dropdowns, lists) including export values and display text",
            "dependencies": [
              2
            ],
            "details": "Parse V (value) entries handling different data types: strings for text fields, names for checkboxes/radio buttons, strings or arrays for choice fields. For choice fields, parse Opt array to extract available options as pairs of export values and display text. Handle special cases like multiple selection in list boxes",
            "status": "done",
            "testStrategy": "Create test cases with pre-filled forms, empty forms, and forms with various option configurations including multi-select lists"
          },
          {
            "id": 4,
            "title": "Extract Field Positioning and Validation Rules",
            "description": "Parse field appearance rectangles for positioning information and extract validation rules including format, range, and custom JavaScript validation",
            "dependencies": [
              2
            ],
            "details": "Extract Rect array from field or widget annotation to determine field bounds on page. Parse validation dictionary (V) for format (AFNumber_Format, AFDate_Format), keystroke validation, and range checks. Extract JavaScript actions from AA (additional actions) dictionary for custom validation. Map page coordinates to consistent coordinate system",
            "status": "done",
            "testStrategy": "Test with forms containing various validation rules, ensure correct coordinate extraction and transformation, verify JavaScript action detection"
          },
          {
            "id": 5,
            "title": "Implement pdf_extract_forms MCP Tool",
            "description": "Create the MCP tool interface that orchestrates the form extraction process and returns structured form field data in the specified JSON format",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Implement the pdf_extract_forms function that: 1) Accepts PDF document input, 2) Calls FormExtractor.ExtractForms to process the document, 3) Transforms extracted data into the FormField model structure, 4) Handles errors gracefully with appropriate error messages, 5) Returns JSON response with array of form fields including all properties, bounds, and validation rules",
            "status": "done",
            "testStrategy": "Integration tests with complete PDF forms, verify end-to-end extraction and JSON output format, test error handling for malformed PDFs"
          }
        ]
      },
      {
        "id": 8,
        "title": "Develop Table Detection Algorithm",
        "description": "Implement spatial analysis algorithms to detect and extract table structures with rows, columns, and cell content",
        "details": "Detect tables using spatial analysis:\n\n```go\n// internal/extractors/tables.go\ntype TableDetector struct {\n    minCellGap   float64\n    alignTolerance float64\n}\n\nfunc (td *TableDetector) DetectTables(texts []ExtractedText) ([]Table, error) {\n    // 1. Find aligned text clusters\n    // 2. Detect column boundaries\n    // 3. Identify row separations\n    // 4. Build cell matrix\n    // 5. Handle merged cells\n}\n\n// pkg/models/table.go\ntype Table struct {\n    Page       int         `json:\"page\"`\n    Bounds     BoundingBox `json:\"bounds\"`\n    Rows       int         `json:\"rows\"`\n    Columns    int         `json:\"columns\"`\n    Cells      [][]Cell    `json:\"cells\"`\n    Confidence float64     `json:\"confidence\"`\n}\n\n// Use heuristics: vertical alignment, consistent spacing, grid patterns\n```\n\nImplement pdf_extract_tables MCP tool.",
        "testStrategy": "Test with various table layouts: simple grids, merged cells, nested tables. Measure detection accuracy and confidence scores. Compare with ground truth annotations.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Advanced Query Engine",
        "description": "Build a query system that allows searching and filtering PDF content by type, position, formatting, and text patterns",
        "details": "Create flexible query interface:\n\n```go\n// internal/query/engine.go\ntype QueryEngine struct {\n    index ContentIndex\n}\n\ntype Query struct {\n    Type      string      `json:\"type,omitempty\"` // text, image, table\n    Pattern   string      `json:\"pattern,omitempty\"`\n    Page      *int        `json:\"page,omitempty\"`\n    Region    *BoundingBox `json:\"region,omitempty\"`\n    FontSize  *float64    `json:\"fontSize,omitempty\"`\n}\n\nfunc (qe *QueryEngine) Query(doc *PDFDocument, query Query) ([]QueryResult, error) {\n    // Parse query parameters\n    // Filter by content type\n    // Apply spatial filters\n    // Match text patterns\n    // Score and rank results\n}\n\n// Support regex patterns, fuzzy matching, proximity search\n```\n\nImplement pdf_query_content MCP tool.",
        "testStrategy": "Test various query combinations: spatial queries, pattern matching, multi-criteria filters. Verify performance with large documents. Test edge cases and invalid queries.",
        "priority": "low",
        "dependencies": [
          6,
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Create Document Intelligence and Analysis Layer",
        "description": "Implement document type classification, structure analysis, and comprehensive document intelligence features",
        "details": "Build document understanding capabilities:\n\n```go\n// internal/intelligence/analyzer.go\ntype DocumentAnalyzer struct {\n    extractors map[string]Extractor\n    classifier *DocumentClassifier\n}\n\nfunc (da *DocumentAnalyzer) Analyze(doc *PDFDocument) (*DocumentAnalysis, error) {\n    // Extract all content types\n    // Detect document structure\n    // Classify document type\n    // Map relationships\n    // Generate insights\n}\n\n// pkg/models/analysis.go\ntype DocumentAnalysis struct {\n    Type       string           `json:\"type\"` // invoice, report, form, etc.\n    Sections   []Section        `json:\"sections\"`\n    Statistics ContentStats     `json:\"statistics\"`\n    Quality    QualityMetrics   `json:\"quality\"`\n    Suggestions []string        `json:\"suggestions\"`\n}\n\n// Use heuristics and patterns for classification\n// Future: integrate ML models for better accuracy\n```\n\nImplement pdf_analyze_document MCP tool.",
        "testStrategy": "Test with diverse document types: invoices, reports, academic papers. Validate classification accuracy. Test section detection and relationship mapping.",
        "priority": "low",
        "dependencies": [
          8,
          9
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Document Content Extractors",
            "description": "Create modular extractors for different content types (text, tables, images, forms) that can parse and structure raw PDF content into analyzable formats",
            "dependencies": [],
            "details": "Create an Extractor interface and implement concrete extractors: TextExtractor for paragraphs and headers, TableExtractor for tabular data, ImageExtractor for embedded images, and FormExtractor for form fields. Each extractor should return structured data with position information and confidence scores.",
            "status": "done",
            "testStrategy": "Unit test each extractor with sample PDF content, verify extraction accuracy and position mapping, test edge cases like rotated text and complex tables"
          },
          {
            "id": 2,
            "title": "Build Document Structure Detection System",
            "description": "Implement algorithms to detect document sections, hierarchies, and logical structure including headers, paragraphs, lists, and their relationships",
            "dependencies": [
              1
            ],
            "details": "Create a StructureDetector that analyzes extracted content to identify document sections, build a hierarchical tree of content relationships, detect reading order, and map spatial relationships between elements. Use font sizes, positioning, and styling to infer structure.",
            "status": "done",
            "testStrategy": "Test with various document types (reports, articles, forms), verify correct hierarchy detection, validate reading order accuracy"
          },
          {
            "id": 3,
            "title": "Create Document Classification Engine",
            "description": "Develop a rule-based document classifier that can identify document types (invoice, report, form, contract, etc.) based on content patterns and structure",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement DocumentClassifier with pattern matching for keywords, structure signatures, and content heuristics. Create classification rules for common document types, implement confidence scoring, and support custom classification rules. Design for future ML model integration.",
            "status": "done",
            "testStrategy": "Test classification accuracy across document types, verify confidence scores, test with ambiguous documents"
          },
          {
            "id": 4,
            "title": "Implement Document Analysis and Insights Generation",
            "description": "Build the core DocumentAnalyzer that orchestrates extractors, structure detection, and classification to produce comprehensive document analysis with statistics and quality metrics",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Implement the DocumentAnalyzer.Analyze method to coordinate all components, calculate content statistics (word count, table count, image count), assess document quality metrics (readability, completeness, formatting consistency), and generate actionable suggestions for document improvement.",
            "status": "done",
            "testStrategy": "Integration test the full analysis pipeline, verify statistics accuracy, validate quality metrics against known documents"
          },
          {
            "id": 5,
            "title": "Create pdf_analyze_document MCP Tool",
            "description": "Implement the Model Context Protocol tool that exposes document analysis capabilities with proper request/response handling and error management",
            "dependencies": [
              4
            ],
            "details": "Create the MCP tool handler that accepts PDF document input, invokes the DocumentAnalyzer, formats the DocumentAnalysis response as JSON, handles errors gracefully, and provides detailed analysis results including type, sections, statistics, quality metrics, and suggestions.",
            "status": "done",
            "testStrategy": "Test MCP tool with various PDF inputs, verify JSON response structure, test error handling for invalid inputs"
          }
        ]
      },
      {
        "id": 11,
        "title": "Research and Integrate PDF Form Library (pdfcpu)",
        "description": "Research and integrate pdfcpu or similar Go library that provides proper AcroForm access according to PDF 1.4/1.7 standards, enabling robust form field extraction capabilities",
        "details": "Research and integrate a PDF library with AcroForm support:\n\n```go\n// internal/pdf/forms/library_adapter.go\ntype FormLibraryAdapter interface {\n    LoadPDF(reader io.Reader) error\n    GetAcroForm() (*AcroForm, error)\n    ExtractFormFields() ([]RawFormField, error)\n}\n\n// internal/pdf/forms/pdfcpu_adapter.go\ntype PDFCPUAdapter struct {\n    ctx *pdfcpu.Context\n}\n\nfunc (p *PDFCPUAdapter) LoadPDF(reader io.Reader) error {\n    // Initialize pdfcpu context\n    // Validate PDF structure\n    // Load form dictionary\n}\n\nfunc (p *PDFCPUAdapter) GetAcroForm() (*AcroForm, error) {\n    // Access AcroForm dictionary\n    // Parse field hierarchy\n    // Extract form metadata\n}\n\n// internal/pdf/forms/field_parser.go\ntype FieldParser struct {\n    adapter FormLibraryAdapter\n}\n\nfunc (fp *FieldParser) ParseField(dict pdfcpu.Dict) (*RawFormField, error) {\n    // Extract field type (FT)\n    // Get field name (T)\n    // Parse field flags (Ff)\n    // Extract default value (DV)\n    // Get current value (V)\n    // Parse appearance streams\n}\n```\n\nResearch considerations:\n1. Evaluate pdfcpu vs other libraries (unipdf, pdfium-go bindings)\n2. Ensure pure Go implementation (no CGO) for portability\n3. Verify PDF 1.4/1.7 standard compliance\n4. Check support for all form field types:\n   - Text fields (Tx)\n   - Checkboxes (Btn with checkbox flag)\n   - Radio buttons (Btn with radio flag)\n   - Dropdown/combo boxes (Ch)\n   - Signature fields (Sig)\n5. Validate handling of field inheritance and merged dictionaries\n6. Test performance with large forms\n\nIntegration approach:\n```go\n// internal/extractors/forms_enhanced.go\ntype EnhancedFormExtractor struct {\n    parser    *pdf.PDFParser\n    adapter   FormLibraryAdapter\n}\n\nfunc (efe *EnhancedFormExtractor) Extract(doc *PDFDocument) ([]FormField, error) {\n    // Use existing parser for basic structure\n    // Leverage library for AcroForm access\n    // Map library fields to our FormField model\n    // Handle field positioning and appearance\n}\n```",
        "testStrategy": "Create comprehensive test suite for library integration:\n\n1. Library evaluation tests:\n   - Test pdfcpu with sample forms from PDF reference\n   - Verify field extraction accuracy\n   - Benchmark performance vs existing implementation\n\n2. Integration tests:\n   - Test with forms containing all field types\n   - Verify field hierarchy parsing\n   - Test inherited field properties\n   - Validate appearance stream handling\n\n3. Compatibility tests:\n   - Test with PDF 1.4 and 1.7 forms\n   - Verify handling of XFA forms (if supported)\n   - Test encrypted/protected forms\n   - Validate Unicode field names and values\n\n4. Edge case tests:\n   - Malformed AcroForm dictionaries\n   - Missing required field properties\n   - Circular field references\n   - Large forms (1000+ fields)\n\n5. Regression tests:\n   - Ensure existing PDF parsing still works\n   - Verify no performance degradation\n   - Test memory usage with large forms",
        "status": "done",
        "dependencies": [
          2,
          7
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement AcroForm Dictionary Parser",
        "description": "Build a specialized parser to extract and process the AcroForm dictionary from PDF catalog, handling the complete form field hierarchy including field inheritance and widget annotations according to PDF 1.7 section 12.7",
        "details": "Implement comprehensive AcroForm dictionary parsing:\n\n```go\n// internal/pdf/forms/acroform_parser.go\ntype AcroFormParser struct {\n    catalog    *PDFCatalog\n    resolver   ObjectResolver\n}\n\ntype AcroForm struct {\n    Fields          []FieldDict    `json:\"fields\"`\n    NeedAppearances bool          `json:\"needAppearances\"`\n    SigFlags        int           `json:\"sigFlags\"`\n    CO              []ObjectRef   `json:\"co,omitempty\"`\n    DR              ResourceDict  `json:\"dr,omitempty\"`\n    DA              string        `json:\"da,omitempty\"`\n    Q               int           `json:\"q,omitempty\"`\n}\n\nfunc (p *AcroFormParser) ParseAcroForm() (*AcroForm, error) {\n    // 1. Get AcroForm entry from catalog\n    acroFormRef := p.catalog.Get(\"AcroForm\")\n    if acroFormRef == nil {\n        return nil, ErrNoAcroForm\n    }\n    \n    // 2. Resolve indirect reference\n    acroFormDict := p.resolver.Resolve(acroFormRef)\n    \n    // 3. Parse AcroForm dictionary entries\n    form := &AcroForm{}\n    \n    // Parse Fields array (required)\n    if fields := acroFormDict.Get(\"Fields\"); fields != nil {\n        form.Fields = p.parseFieldArray(fields)\n    }\n    \n    // Parse optional entries\n    form.NeedAppearances = acroFormDict.GetBool(\"NeedAppearances\", false)\n    form.SigFlags = acroFormDict.GetInt(\"SigFlags\", 0)\n    form.DA = acroFormDict.GetString(\"DA\", \"\")\n    form.Q = acroFormDict.GetInt(\"Q\", 0)\n    \n    return form, nil\n}\n\n// internal/pdf/forms/field_parser.go\ntype FieldDict struct {\n    Type       string              `json:\"type\"`       // FT entry\n    Parent     *ObjectRef          `json:\"parent,omitempty\"`\n    Kids       []FieldDict         `json:\"kids,omitempty\"`\n    T          string              `json:\"t\"`          // Partial field name\n    TU         string              `json:\"tu,omitempty\"` // Alternate name\n    TM         string              `json:\"tm,omitempty\"` // Mapping name\n    Ff         uint32              `json:\"ff,omitempty\"` // Field flags\n    V          interface{}         `json:\"v,omitempty\"`  // Field value\n    DV         interface{}         `json:\"dv,omitempty\"` // Default value\n    AA         map[string]Action   `json:\"aa,omitempty\"` // Additional actions\n    Widgets    []WidgetAnnotation  `json:\"widgets,omitempty\"`\n}\n\nfunc (p *AcroFormParser) parseFieldArray(fieldsObj Object) []FieldDict {\n    var fields []FieldDict\n    \n    if array, ok := fieldsObj.(ArrayObject); ok {\n        for _, fieldRef := range array {\n            field := p.parseFieldDict(fieldRef)\n            if field != nil {\n                fields = append(fields, *field)\n            }\n        }\n    }\n    \n    return fields\n}\n\nfunc (p *AcroFormParser) parseFieldDict(fieldRef Object) *FieldDict {\n    // Resolve indirect reference\n    fieldObj := p.resolver.Resolve(fieldRef)\n    dict, ok := fieldObj.(DictObject)\n    if !ok {\n        return nil\n    }\n    \n    field := &FieldDict{}\n    \n    // Parse field type (may be inherited)\n    field.Type = p.getInheritedValue(dict, \"FT\").(string)\n    \n    // Parse field name components\n    field.T = dict.GetString(\"T\", \"\")\n    field.TU = dict.GetString(\"TU\", \"\")\n    field.TM = dict.GetString(\"TM\", \"\")\n    \n    // Parse field flags (inheritable)\n    if ff := p.getInheritedValue(dict, \"Ff\"); ff != nil {\n        field.Ff = uint32(ff.(int))\n    }\n    \n    // Parse value and default value\n    field.V = p.parseFieldValue(dict.Get(\"V\"), field.Type)\n    field.DV = p.parseFieldValue(dict.Get(\"DV\"), field.Type)\n    \n    // Handle field hierarchy\n    if kids := dict.Get(\"Kids\"); kids != nil {\n        field.Kids = p.parseFieldArray(kids)\n    } else {\n        // Terminal field - parse widget annotations\n        field.Widgets = p.parseWidgetAnnotations(dict)\n    }\n    \n    return field\n}\n\n// Handle field inheritance according to PDF spec\nfunc (p *AcroFormParser) getInheritedValue(field DictObject, key string) interface{} {\n    // Check current field\n    if val := field.Get(key); val != nil {\n        return val\n    }\n    \n    // Check parent hierarchy\n    parent := field.Get(\"Parent\")\n    for parent != nil {\n        parentDict := p.resolver.Resolve(parent).(DictObject)\n        if val := parentDict.Get(key); val != nil {\n            return val\n        }\n        parent = parentDict.Get(\"Parent\")\n    }\n    \n    return nil\n}\n\n// internal/pdf/forms/widget_parser.go\ntype WidgetAnnotation struct {\n    Rect       Rectangle          `json:\"rect\"`\n    Page       int                `json:\"page\"`\n    AP         AppearanceDict     `json:\"ap,omitempty\"`\n    AS         string             `json:\"as,omitempty\"`\n    Border     []float64          `json:\"border,omitempty\"`\n    C          []float64          `json:\"c,omitempty\"`\n    StructParent int              `json:\"structParent,omitempty\"`\n}\n\nfunc (p *AcroFormParser) parseWidgetAnnotations(field DictObject) []WidgetAnnotation {\n    var widgets []WidgetAnnotation\n    \n    // Check if field is merged with widget\n    if rect := field.Get(\"Rect\"); rect != nil {\n        widget := p.parseWidgetAnnotation(field)\n        widgets = append(widgets, widget)\n    }\n    \n    // Check for separate widget annotations\n    if annots := field.Get(\"Kids\"); annots != nil {\n        // Parse child widgets\n        for _, annotRef := range annots.(ArrayObject) {\n            annotDict := p.resolver.Resolve(annotRef).(DictObject)\n            if annotDict.GetName(\"Subtype\") == \"Widget\" {\n                widget := p.parseWidgetAnnotation(annotDict)\n                widgets = append(widgets, widget)\n            }\n        }\n    }\n    \n    return widgets\n}\n\n// Field value parsing based on field type\nfunc (p *AcroFormParser) parseFieldValue(val Object, fieldType string) interface{} {\n    if val == nil {\n        return nil\n    }\n    \n    switch fieldType {\n    case \"Tx\": // Text field\n        return p.resolver.ResolveString(val)\n    case \"Ch\": // Choice field\n        if array, ok := val.(ArrayObject); ok {\n            var options []string\n            for _, opt := range array {\n                options = append(options, p.resolver.ResolveString(opt))\n            }\n            return options\n        }\n        return p.resolver.ResolveString(val)\n    case \"Btn\": // Button field\n        if name, ok := val.(NameObject); ok {\n            return string(name)\n        }\n        return nil\n    default:\n        return val\n    }\n}\n```\n\nKey implementation considerations:\n1. Handle field inheritance properly - FT, Ff, V, DV can be inherited from ancestors\n2. Support merged fields (field dict contains widget properties) and separate widgets\n3. Parse all field types: text (Tx), button (Btn), choice (Ch), signature (Sig)\n4. Handle field naming hierarchy with fully qualified names\n5. Support field collections and calculation order (CO array)\n6. Parse default resources (DR) and default appearance (DA)",
        "testStrategy": "Comprehensive testing for AcroForm dictionary parsing:\n\n1. **Basic AcroForm parsing tests**:\n   - Test with PDFs containing valid AcroForm dictionaries\n   - Verify correct parsing of all AcroForm entries (Fields, NeedAppearances, SigFlags, etc.)\n   - Test with missing optional entries\n   - Test with PDFs that have no forms (should return appropriate error)\n\n2. **Field hierarchy tests**:\n   - Create test PDFs with nested field hierarchies\n   - Verify field inheritance works correctly (FT, Ff, V, DV)\n   - Test fully qualified field name construction\n   - Test with deeply nested field trees (3+ levels)\n\n3. **Field type specific tests**:\n   - Text fields: single line, multiline, password, file select\n   - Button fields: push buttons, checkboxes, radio buttons\n   - Choice fields: list boxes, combo boxes, multi-select\n   - Signature fields with various states\n\n4. **Widget annotation tests**:\n   - Test merged field/widget dictionaries\n   - Test separate widget annotations in Kids array\n   - Verify correct page association for widgets\n   - Test appearance streams (AP dictionary)\n\n5. **Edge cases and error handling**:\n   - Circular references in field hierarchy\n   - Invalid field types\n   - Malformed field dictionaries\n   - Missing required entries\n   - Test with PDF 1.4 and 1.7 form variations\n\n6. **Integration tests**:\n   - Parse real-world PDF forms from Adobe, government forms, etc.\n   - Compare output with reference implementations\n   - Verify all field properties are correctly extracted\n   - Test performance with forms containing 100+ fields\n\nTest data should include example PDFs from PDF reference documentation and real-world forms with various complexity levels.",
        "status": "done",
        "dependencies": [
          2,
          11
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Create PDF Library Wrapper Interface",
        "description": "Design and implement an abstraction layer that provides a unified interface for PDF operations, allowing seamless switching between ledongthuc/pdf, pdfcpu, or custom implementations",
        "details": "Create a flexible PDF library wrapper that abstracts common operations:\n\n```go\n// internal/pdf/wrapper/interface.go\ntype PDFLibrary interface {\n    // Core operations\n    Open(reader io.Reader) (PDFDocument, error)\n    OpenFile(path string) (PDFDocument, error)\n    Validate() error\n    Close() error\n    \n    // Metadata operations\n    GetMetadata() (*Metadata, error)\n    GetPageCount() (int, error)\n    GetVersion() (string, error)\n    \n    // Content extraction\n    ExtractText(pageNum int) ([]TextElement, error)\n    ExtractImages(pageNum int) ([]ImageElement, error)\n    ExtractForms() ([]FormField, error)\n    \n    // Advanced operations\n    GetContentStream(pageNum int) ([]byte, error)\n    GetPageResources(pageNum int) (*Resources, error)\n    GetCatalog() (*Catalog, error)\n}\n\n// internal/pdf/wrapper/factory.go\ntype LibraryType string\n\nconst (\n    LibraryCustom    LibraryType = \"custom\"\n    LibraryPDFCPU    LibraryType = \"pdfcpu\"\n    LibraryLedongthuc LibraryType = \"ledongthuc\"\n)\n\ntype PDFLibraryFactory struct {\n    defaultLib LibraryType\n}\n\nfunc (f *PDFLibraryFactory) Create(libType LibraryType) (PDFLibrary, error) {\n    switch libType {\n    case LibraryCustom:\n        return &CustomPDFLibrary{}, nil\n    case LibraryPDFCPU:\n        return &PDFCPULibrary{}, nil\n    case LibraryLedongthuc:\n        return &LedongthucLibrary{}, nil\n    default:\n        return nil, fmt.Errorf(\"unknown library type: %s\", libType)\n    }\n}\n\n// internal/pdf/wrapper/custom.go\ntype CustomPDFLibrary struct {\n    parser *PDFParser\n    doc    *PDFDocument\n}\n\nfunc (c *CustomPDFLibrary) Open(reader io.Reader) (PDFDocument, error) {\n    // Use existing custom parser implementation\n    c.parser = NewPDFParser(reader)\n    return c.parser.Parse()\n}\n\n// internal/pdf/wrapper/pdfcpu.go\ntype PDFCPULibrary struct {\n    ctx *pdfcpu.Context\n}\n\nfunc (p *PDFCPULibrary) Open(reader io.Reader) (PDFDocument, error) {\n    // Wrap pdfcpu operations\n    config := pdfcpu.NewDefaultConfiguration()\n    ctx, err := pdfcpu.Read(reader, config)\n    if err != nil {\n        return nil, err\n    }\n    p.ctx = ctx\n    return p.wrapDocument(), nil\n}\n\n// internal/pdf/wrapper/ledongthuc.go\ntype LedongthucLibrary struct {\n    pdf *ledongthuc.PDF\n}\n\nfunc (l *LedongthucLibrary) Open(reader io.Reader) (PDFDocument, error) {\n    // Wrap ledongthuc/pdf operations\n    pdf, err := ledongthuc.NewPDF(reader)\n    if err != nil {\n        return nil, err\n    }\n    l.pdf = pdf\n    return l.wrapDocument(), nil\n}\n\n// Common types for unified interface\ntype PDFDocument interface {\n    GetPage(num int) (PDFPage, error)\n    GetPageCount() int\n    GetMetadata() map[string]string\n}\n\ntype TextElement struct {\n    Text     string\n    Position Point\n    Font     FontInfo\n    Size     float64\n}\n\n// Configuration for library selection\ntype WrapperConfig struct {\n    PreferredLibrary LibraryType\n    Fallbacks        []LibraryType\n    Features         []string // Required features for library selection\n}\n\n// Smart library selector based on document characteristics\nfunc SelectOptimalLibrary(doc io.Reader, config WrapperConfig) (PDFLibrary, error) {\n    // Analyze document to determine best library\n    // Check for specific features (forms, encryption, etc.)\n    // Return most suitable implementation\n}\n```\n\nImplement adapter pattern for each library to ensure consistent behavior and error handling across implementations.",
        "testStrategy": "Comprehensive testing strategy for the wrapper interface:\n\n1. **Interface compliance tests**:\n   - Verify all implementations satisfy PDFLibrary interface\n   - Test method signatures and return types\n   - Ensure consistent error types across implementations\n\n2. **Functional equivalence tests**:\n   - Create test suite that runs against all three implementations\n   - Compare extracted text, images, and metadata\n   - Verify identical results for same PDF inputs\n   - Test with PDFs from docs/examples/\n\n3. **Performance benchmarks**:\n   - Benchmark each implementation for common operations\n   - Compare memory usage and processing speed\n   - Test with large PDFs (100+ pages)\n\n4. **Feature coverage matrix**:\n   - Test form extraction capabilities per library\n   - Verify image extraction support\n   - Check Unicode and encoding handling\n   - Test encrypted PDF support\n\n5. **Fallback mechanism tests**:\n   - Test automatic fallback when preferred library fails\n   - Verify graceful degradation of features\n   - Test library selection logic\n\n6. **Integration tests**:\n   - Test wrapper with existing extractors\n   - Verify MCP server works with all implementations\n   - Test hot-swapping of libraries at runtime",
        "status": "done",
        "dependencies": [
          2,
          11
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement pdfcpu Backend for PDF Wrapper",
        "description": "Create a pdfcpu-based implementation of the PDFLibrary interface that provides robust AcroForm extraction capabilities with proper field type detection, value extraction, and property handling according to PDF specifications",
        "details": "Implement a complete pdfcpu backend for the PDF wrapper interface with focus on AcroForm functionality:\n\n```go\n// internal/pdf/wrapper/pdfcpu_backend.go\npackage wrapper\n\nimport (\n    \"github.com/pdfcpu/pdfcpu/pkg/api\"\n    \"github.com/pdfcpu/pdfcpu/pkg/pdfcpu\"\n    \"github.com/pdfcpu/pdfcpu/pkg/pdfcpu/model\"\n)\n\ntype PDFCPUBackend struct {\n    ctx      *model.Context\n    reader   io.Reader\n    filePath string\n}\n\nfunc NewPDFCPUBackend() *PDFCPUBackend {\n    return &PDFCPUBackend{}\n}\n\nfunc (p *PDFCPUBackend) Open(reader io.Reader) (PDFDocument, error) {\n    // Read PDF into memory\n    data, err := io.ReadAll(reader)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to read PDF: %w\", err)\n    }\n    \n    // Parse with pdfcpu\n    ctx, err := api.ReadContext(bytes.NewReader(data), pdfcpu.NewDefaultConfiguration())\n    if err != nil {\n        return nil, fmt.Errorf(\"pdfcpu parse error: %w\", err)\n    }\n    \n    p.ctx = ctx\n    p.reader = bytes.NewReader(data)\n    return p, nil\n}\n\n// Implement AcroForm extraction with full field support\nfunc (p *PDFCPUBackend) ExtractFormFields() ([]FormField, error) {\n    if p.ctx.AcroForm == nil {\n        return []FormField{}, nil\n    }\n    \n    fields := []FormField{}\n    \n    // Process field tree recursively\n    for _, fieldRef := range p.ctx.AcroForm.Fields {\n        field, err := p.processFieldTree(fieldRef)\n        if err != nil {\n            continue // Log error but continue processing\n        }\n        fields = append(fields, field...)\n    }\n    \n    return fields, nil\n}\n\nfunc (p *PDFCPUBackend) processFieldTree(fieldRef model.Object) ([]FormField, error) {\n    fieldDict, err := p.ctx.DereferenceDict(fieldRef)\n    if err != nil {\n        return nil, err\n    }\n    \n    fields := []FormField{}\n    \n    // Check if this is a terminal field or intermediate node\n    if kids := fieldDict.ArrayEntry(\"Kids\"); kids != nil {\n        // Process children\n        for _, kidRef := range kids {\n            childFields, err := p.processFieldTree(kidRef)\n            if err != nil {\n                continue\n            }\n            fields = append(fields, childFields...)\n        }\n    } else {\n        // Terminal field - extract properties\n        field, err := p.extractFieldProperties(fieldDict)\n        if err != nil {\n            return nil, err\n        }\n        fields = append(fields, *field)\n    }\n    \n    return fields, nil\n}\n\nfunc (p *PDFCPUBackend) extractFieldProperties(dict model.Dict) (*FormField, error) {\n    field := &FormField{\n        Properties: make(map[string]interface{}),\n    }\n    \n    // Extract field name (handle inheritance)\n    field.Name = p.getInheritedFieldName(dict)\n    \n    // Determine field type\n    ft := dict.NameEntry(\"FT\")\n    if ft == nil {\n        ft = p.getInheritedEntry(dict, \"FT\")\n    }\n    \n    switch ft.String() {\n    case \"Tx\":\n        field.Type = \"text\"\n        field.Properties[\"multiline\"] = dict.BooleanEntry(\"Ff\")&4096 != 0\n        field.Properties[\"password\"] = dict.BooleanEntry(\"Ff\")&8192 != 0\n        field.Properties[\"maxLength\"] = dict.IntEntry(\"MaxLen\")\n    case \"Btn\":\n        flags := dict.IntEntry(\"Ff\")\n        if flags&65536 != 0 { // Pushbutton\n            field.Type = \"button\"\n        } else if flags&32768 != 0 { // Radio\n            field.Type = \"radio\"\n        } else { // Checkbox\n            field.Type = \"checkbox\"\n        }\n    case \"Ch\":\n        flags := dict.IntEntry(\"Ff\")\n        if flags&131072 != 0 { // Combo\n            field.Type = \"combobox\"\n        } else {\n            field.Type = \"listbox\"\n        }\n        field.Properties[\"multiSelect\"] = flags&2097152 != 0\n        \n        // Extract options\n        if opt := dict.ArrayEntry(\"Opt\"); opt != nil {\n            field.Options = p.extractOptions(opt)\n        }\n    case \"Sig\":\n        field.Type = \"signature\"\n    }\n    \n    // Extract value\n    field.Value = p.extractFieldValue(dict, field.Type)\n    \n    // Extract common properties\n    field.Properties[\"readOnly\"] = dict.IntEntry(\"Ff\")&1 != 0\n    field.Properties[\"required\"] = dict.IntEntry(\"Ff\")&2 != 0\n    field.Properties[\"noExport\"] = dict.IntEntry(\"Ff\")&4 != 0\n    \n    // Extract appearance and position\n    if widgets := p.getWidgetAnnotations(dict); len(widgets) > 0 {\n        // Use first widget for position\n        widget := widgets[0]\n        if rect := widget.ArrayEntry(\"Rect\"); rect != nil && len(rect) == 4 {\n            field.Bounds = &BoundingBox{\n                X1: rect[0].(model.Float),\n                Y1: rect[1].(model.Float),\n                X2: rect[2].(model.Float),\n                Y2: rect[3].(model.Float),\n            }\n        }\n    }\n    \n    // Extract default value\n    if dv := dict.Entry(\"DV\"); dv != nil {\n        field.DefaultValue = p.objectToValue(dv)\n    }\n    \n    // Extract tooltip/alternate text\n    if tu := dict.StringEntry(\"TU\"); tu != nil {\n        field.Properties[\"tooltip\"] = *tu\n    }\n    \n    return field, nil\n}\n\nfunc (p *PDFCPUBackend) extractFieldValue(dict model.Dict, fieldType string) interface{} {\n    v := dict.Entry(\"V\")\n    if v == nil {\n        return nil\n    }\n    \n    switch fieldType {\n    case \"checkbox\":\n        // Check for /Yes or checked state\n        if name, ok := v.(model.Name); ok {\n            return name.String() == \"Yes\"\n        }\n    case \"radio\":\n        // Return the selected option name\n        if name, ok := v.(model.Name); ok {\n            return name.String()\n        }\n    case \"text\", \"combobox\":\n        // Return string value\n        if str := dict.StringEntry(\"V\"); str != nil {\n            return *str\n        }\n    case \"listbox\":\n        // Can be single or multiple values\n        if arr, ok := v.(model.Array); ok {\n            values := []string{}\n            for _, item := range arr {\n                if str, ok := item.(model.StringLiteral); ok {\n                    values = append(values, str.Value())\n                }\n            }\n            return values\n        } else if str := dict.StringEntry(\"V\"); str != nil {\n            return []string{*str}\n        }\n    }\n    \n    return p.objectToValue(v)\n}\n\n// Helper to convert PDF objects to Go values\nfunc (p *PDFCPUBackend) objectToValue(obj model.Object) interface{} {\n    switch v := obj.(type) {\n    case model.StringLiteral:\n        return v.Value()\n    case model.Name:\n        return v.String()\n    case model.Integer:\n        return int(v)\n    case model.Float:\n        return float64(v)\n    case model.Boolean:\n        return bool(v)\n    case model.Array:\n        arr := []interface{}{}\n        for _, item := range v {\n            arr = append(arr, p.objectToValue(item))\n        }\n        return arr\n    default:\n        return nil\n    }\n}\n\n// Implement other PDFLibrary interface methods\nfunc (p *PDFCPUBackend) ExtractText(pageNum int) ([]ExtractedText, error) {\n    // Use pdfcpu's text extraction\n    text, err := api.ExtractPageContent(p.ctx, pageNum)\n    if err != nil {\n        return nil, err\n    }\n    \n    // Convert to our format\n    // Note: pdfcpu may not provide positioned text, so this might need enhancement\n    return []ExtractedText{\n        {\n            Text: text,\n            Page: pageNum,\n        },\n    }, nil\n}\n\nfunc (p *PDFCPUBackend) GetMetadata() (*Metadata, error) {\n    info := p.ctx.Info\n    if info == nil {\n        return &Metadata{}, nil\n    }\n    \n    return &Metadata{\n        Title:        info.Title,\n        Author:       info.Author,\n        Subject:      info.Subject,\n        Keywords:     info.Keywords,\n        Creator:      info.Creator,\n        Producer:     info.Producer,\n        CreationDate: info.CreationDate,\n        ModDate:      info.ModDate,\n    }, nil\n}\n```\n\nAdditional implementation considerations:\n\n1. **Field inheritance handling**: PDF form fields can inherit properties from parent fields\n```go\nfunc (p *PDFCPUBackend) getInheritedFieldName(dict model.Dict) string {\n    parts := []string{}\n    current := dict\n    \n    for current != nil {\n        if t := current.StringEntry(\"T\"); t != nil {\n            parts = append([]string{*t}, parts...)\n        }\n        \n        // Move to parent\n        if parent := current.DictEntry(\"Parent\"); parent != nil {\n            current = parent\n        } else {\n            break\n        }\n    }\n    \n    return strings.Join(parts, \".\")\n}\n```\n\n2. **Widget annotation handling**: Form fields can have multiple widget annotations\n```go\nfunc (p *PDFCPUBackend) getWidgetAnnotations(fieldDict model.Dict) []model.Dict {\n    widgets := []model.Dict{}\n    \n    // Check if field dict is also a widget (merged)\n    if fieldDict.Entry(\"Subtype\") == model.Name(\"Widget\") {\n        widgets = append(widgets, fieldDict)\n    }\n    \n    // Check Kids for widgets\n    if kids := fieldDict.ArrayEntry(\"Kids\"); kids != nil {\n        for _, kid := range kids {\n            if kidDict, err := p.ctx.DereferenceDict(kid); err == nil {\n                if kidDict.Entry(\"Subtype\") == model.Name(\"Widget\") {\n                    widgets = append(widgets, kidDict)\n                }\n            }\n        }\n    }\n    \n    return widgets\n}\n```\n\n3. **Configuration and optimization**:\n```go\nfunc (p *PDFCPUBackend) Configure(opts PDFOptions) error {\n    config := pdfcpu.NewDefaultConfiguration()\n    config.ValidationMode = pdfcpu.ValidationRelaxed // For better compatibility\n    config.OptimizeDuplicateContentStreams = true\n    \n    // Apply custom options\n    if opts.StrictValidation {\n        config.ValidationMode = pdfcpu.ValidationStrict\n    }\n    \n    p.config = config\n    return nil\n}\n```",
        "testStrategy": "Comprehensive testing strategy for pdfcpu backend implementation:\n\n1. **Unit tests for field extraction**:\n   - Test each field type (text, checkbox, radio, combobox, listbox, signature)\n   - Verify correct value extraction for filled and empty fields\n   - Test field property extraction (required, readonly, multiline, etc.)\n   - Test field name inheritance from parent fields\n   - Test default value extraction\n\n2. **Integration tests with real PDFs**:\n   - Use IRS tax forms (complex field hierarchies)\n   - Test with Adobe sample forms from PDF reference\n   - Test with forms created by different PDF generators\n   - Verify extraction matches expected field structure\n\n3. **Edge case testing**:\n   - Forms with no AcroForm dictionary\n   - Malformed field dictionaries\n   - Fields with missing required entries\n   - Deeply nested field hierarchies\n   - Fields with multiple widget annotations\n   - Unicode field names and values\n\n4. **Performance benchmarks**:\n   - Compare extraction speed with native implementation\n   - Memory usage profiling for large forms\n   - Concurrent form extraction testing\n\n5. **Compatibility testing**:\n   - Test with PDF 1.4 through 2.0 forms\n   - XFA forms (should gracefully handle as unsupported)\n   - Hybrid AcroForm/XFA documents\n   - Encrypted PDFs with form fields\n\n6. **Validation against PDF specification**:\n   - Verify field flag interpretation matches PDF 1.7 spec\n   - Test appearance stream handling\n   - Validate field value formatting\n   - Check calculation order (CO array) handling\n\nTest implementation example:\n```go\nfunc TestPDFCPUFormExtraction(t *testing.T) {\n    backend := NewPDFCPUBackend()\n    \n    testCases := []struct {\n        name     string\n        pdfPath  string\n        expected []FormField\n    }{\n        {\n            name:    \"simple_text_form\",\n            pdfPath: \"testdata/forms/simple_text.pdf\",\n            expected: []FormField{\n                {\n                    Name:  \"name\",\n                    Type:  \"text\",\n                    Value: \"John Doe\",\n                    Properties: map[string]interface{}{\n                        \"maxLength\": 50,\n                    },\n                },\n            },\n        },\n        // More test cases...\n    }\n    \n    for _, tc := range testCases {\n        t.Run(tc.name, func(t *testing.T) {\n            file, _ := os.Open(tc.pdfPath)\n            defer file.Close()\n            \n            doc, err := backend.Open(file)\n            require.NoError(t, err)\n            \n            fields, err := doc.ExtractFormFields()\n            require.NoError(t, err)\n            \n            assert.Equal(t, tc.expected, fields)\n        })\n    }\n}\n```",
        "status": "done",
        "dependencies": [
          11,
          12,
          13
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Design and Implement Custom PDF Parser from Scratch",
        "description": "Build a complete PDF parser from scratch following PDF 1.4/1.7 specifications, providing full control over form extraction and document parsing without relying on external libraries",
        "details": "Implement a comprehensive PDF parser with complete control over parsing logic:\n\n```go\n// internal/pdf/custom/parser.go\npackage custom\n\ntype CustomPDFParser struct {\n    reader      io.ReadSeeker\n    version     string\n    xrefTable   *CrossReferenceTable\n    trailer     Dictionary\n    catalog     *Catalog\n    pageTree    *PageTree\n    objectCache map[ObjectID]PDFObject\n}\n\n// Core parsing methods\nfunc (p *CustomPDFParser) Parse() error {\n    // 1. Parse PDF header\n    if err := p.parseHeader(); err != nil {\n        return fmt.Errorf(\"header parse failed: %w\", err)\n    }\n    \n    // 2. Locate and parse xref table\n    if err := p.parseXRefTable(); err != nil {\n        return fmt.Errorf(\"xref parse failed: %w\", err)\n    }\n    \n    // 3. Parse trailer dictionary\n    if err := p.parseTrailer(); err != nil {\n        return fmt.Errorf(\"trailer parse failed: %w\", err)\n    }\n    \n    // 4. Load document catalog\n    if err := p.loadCatalog(); err != nil {\n        return fmt.Errorf(\"catalog load failed: %w\", err)\n    }\n    \n    return nil\n}\n\n// internal/pdf/custom/lexer.go\ntype PDFLexer struct {\n    reader   *bufio.Reader\n    position int64\n    buffer   []byte\n}\n\nfunc (l *PDFLexer) NextToken() (Token, error) {\n    // Skip whitespace\n    // Identify token type: number, string, name, array, dict, etc.\n    // Return parsed token\n}\n\n// internal/pdf/custom/objects.go\ntype PDFObject interface {\n    Type() ObjectType\n    String() string\n}\n\ntype Dictionary map[Name]PDFObject\ntype Array []PDFObject\ntype Stream struct {\n    Dict Dictionary\n    Data []byte\n}\n\n// internal/pdf/custom/acroform.go\ntype AcroFormParser struct {\n    parser     *CustomPDFParser\n    formDict   Dictionary\n    fieldCache map[string]*FormField\n}\n\nfunc (a *AcroFormParser) ParseAcroForm(catalog Dictionary) (*AcroForm, error) {\n    // Extract AcroForm dictionary\n    acroFormObj := catalog.Get(\"AcroForm\")\n    if acroFormObj == nil {\n        return nil, nil // No forms\n    }\n    \n    // Parse form dictionary\n    formDict, err := a.parser.resolveIndirectObject(acroFormObj)\n    if err != nil {\n        return err\n    }\n    \n    // Parse field tree\n    fields, err := a.parseFieldTree(formDict.Get(\"Fields\"))\n    if err != nil {\n        return err\n    }\n    \n    return &AcroForm{\n        Fields:          fields,\n        NeedAppearances: formDict.GetBool(\"NeedAppearances\"),\n        SigFlags:        formDict.GetInt(\"SigFlags\"),\n        CO:              a.parseCO(formDict.Get(\"CO\")),\n        DR:              a.parseResources(formDict.Get(\"DR\")),\n        DA:              formDict.GetString(\"DA\"),\n        Q:               formDict.GetInt(\"Q\"),\n    }, nil\n}\n\nfunc (a *AcroFormParser) parseFieldTree(fieldsObj PDFObject) ([]*FormField, error) {\n    // Handle field inheritance\n    // Parse field dictionaries recursively\n    // Resolve widget annotations\n    // Extract field values and properties\n}\n\n// internal/pdf/custom/content_stream.go\ntype ContentStreamParser struct {\n    lexer    *PDFLexer\n    graphics *GraphicsState\n    resources Dictionary\n}\n\nfunc (c *ContentStreamParser) Parse(stream []byte) ([]ContentObject, error) {\n    // Parse PDF content stream operators\n    // Handle text, graphics, and image operators\n    // Track graphics state changes\n    // Extract positioned content\n}\n\n// internal/pdf/custom/filters.go\ntype FilterDecoder interface {\n    Decode(data []byte, params Dictionary) ([]byte, error)\n}\n\nvar filterDecoders = map[string]FilterDecoder{\n    \"FlateDecode\":    &FlateDecoder{},\n    \"ASCIIHexDecode\": &ASCIIHexDecoder{},\n    \"ASCII85Decode\":  &ASCII85Decoder{},\n    \"LZWDecode\":      &LZWDecoder{},\n    \"RunLengthDecode\": &RunLengthDecoder{},\n}\n\n// internal/pdf/custom/encryption.go\ntype EncryptionHandler struct {\n    algorithm string\n    keyLength int\n    permissions uint32\n}\n\nfunc (e *EncryptionHandler) DecryptObject(obj PDFObject, objID ObjectID) (PDFObject, error) {\n    // Handle standard security handler\n    // Support RC4 and AES encryption\n    // Decrypt strings and streams\n}\n\n// Integration with wrapper interface\ntype CustomPDFBackend struct {\n    parser *CustomPDFParser\n}\n\nfunc (c *CustomPDFBackend) Open(reader io.Reader) (PDFDocument, error) {\n    seeker, ok := reader.(io.ReadSeeker)\n    if !ok {\n        // Buffer the reader if not seekable\n        data, err := io.ReadAll(reader)\n        if err != nil {\n            return nil, err\n        }\n        seeker = bytes.NewReader(data)\n    }\n    \n    parser := &CustomPDFParser{\n        reader:      seeker,\n        objectCache: make(map[ObjectID]PDFObject),\n    }\n    \n    if err := parser.Parse(); err != nil {\n        return nil, err\n    }\n    \n    return &customDocument{parser: parser}, nil\n}\n\nfunc (c *CustomPDFBackend) ExtractFormFields() ([]FormField, error) {\n    acroParser := &AcroFormParser{\n        parser:     c.parser,\n        fieldCache: make(map[string]*FormField),\n    }\n    \n    acroForm, err := acroParser.ParseAcroForm(c.parser.catalog)\n    if err != nil {\n        return nil, err\n    }\n    \n    if acroForm == nil {\n        return []FormField{}, nil\n    }\n    \n    return acroParser.ConvertToFormFields(acroForm.Fields)\n}",
        "testStrategy": "Comprehensive testing strategy for custom PDF parser:\n\n1. **PDF structure parsing tests**:\n   - Test header parsing for various PDF versions (1.0-1.7)\n   - Verify cross-reference table parsing (standard and compressed)\n   - Test trailer dictionary extraction\n   - Validate object parsing for all PDF object types\n\n2. **AcroForm parsing tests**:\n   - Test with PDF reference example forms\n   - Verify field inheritance handling\n   - Test all field types: text, checkbox, radio, combo, list, signature\n   - Validate field value extraction and formatting\n   - Test with nested field hierarchies\n\n3. **Content stream parsing tests**:\n   - Test all text operators (BT, ET, Tf, Tm, Tj, TJ, etc.)\n   - Verify graphics state tracking\n   - Test coordinate transformations\n   - Validate font and encoding handling\n\n4. **Filter and encryption tests**:\n   - Test all standard filters (Flate, ASCII85, etc.)\n   - Verify encryption/decryption with test PDFs\n   - Test password-protected documents\n\n5. **Integration tests**:\n   - Compare output with pdfcpu for same documents\n   - Verify form field extraction matches expected values\n   - Test with real-world PDF forms\n   - Performance benchmarks vs other implementations\n\n6. **Error handling tests**:\n   - Test with malformed PDFs\n   - Verify graceful handling of missing objects\n   - Test recovery from parsing errors",
        "status": "pending",
        "dependencies": [
          2,
          12,
          13,
          "14"
        ],
        "priority": "low",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Code Signing for Release Binaries",
        "description": "Set up automated code signing infrastructure for all platform binaries (macOS, Windows, Linux) with certificate management and GitHub Actions integration to ensure release artifacts are properly signed and trusted.",
        "details": "Implement comprehensive code signing solution for multi-platform releases:\n\n```yaml\n# .github/workflows/release.yml\nname: Release with Code Signing\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  sign-macos:\n    runs-on: macos-latest\n    steps:\n      - name: Import Apple Developer Certificate\n        env:\n          APPLE_CERT_BASE64: ${{ secrets.APPLE_CERT_BASE64 }}\n          APPLE_CERT_PASSWORD: ${{ secrets.APPLE_CERT_PASSWORD }}\n        run: |\n          echo \"$APPLE_CERT_BASE64\" | base64 --decode > certificate.p12\n          security create-keychain -p actions temp.keychain\n          security import certificate.p12 -k temp.keychain -P \"$APPLE_CERT_PASSWORD\" -T /usr/bin/codesign\n          security set-key-partition-list -S apple-tool:,apple:,codesign: -s -k actions temp.keychain\n      \n      - name: Sign macOS Binary\n        run: |\n          codesign --deep --force --verify --verbose \\\n            --sign \"${{ secrets.APPLE_DEVELOPER_ID }}\" \\\n            --options runtime \\\n            --entitlements entitlements.plist \\\n            ./dist/pdfextract-darwin-amd64\n          \n      - name: Notarize macOS Binary\n        run: |\n          xcrun altool --notarize-app \\\n            --primary-bundle-id \"com.pdfextract.cli\" \\\n            --username \"${{ secrets.APPLE_ID }}\" \\\n            --password \"${{ secrets.APPLE_APP_PASSWORD }}\" \\\n            --file ./dist/pdfextract-darwin-amd64.zip\n\n  sign-windows:\n    runs-on: windows-latest\n    steps:\n      - name: Setup Windows Code Signing\n        env:\n          WINDOWS_CERT_BASE64: ${{ secrets.WINDOWS_CERT_BASE64 }}\n          WINDOWS_CERT_PASSWORD: ${{ secrets.WINDOWS_CERT_PASSWORD }}\n        run: |\n          $cert = [System.Convert]::FromBase64String($env:WINDOWS_CERT_BASE64)\n          [System.IO.File]::WriteAllBytes(\"certificate.pfx\", $cert)\n          \n      - name: Sign Windows Binary\n        run: |\n          & \"C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.19041.0\\x64\\signtool.exe\" sign `\n            /f certificate.pfx `\n            /p $env:WINDOWS_CERT_PASSWORD `\n            /t http://timestamp.digicert.com `\n            /fd SHA256 `\n            /v .\\dist\\pdfextract-windows-amd64.exe\n\n  sign-linux:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Setup GPG Signing\n        env:\n          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}\n          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}\n        run: |\n          echo \"$GPG_PRIVATE_KEY\" | gpg --batch --import\n          echo \"$GPG_PASSPHRASE\" | gpg --batch --yes --passphrase-fd 0 --pinentry-mode loopback \\\n            --detach-sign --armor ./dist/pdfextract-linux-amd64\n```\n\nCreate certificate management scripts:\n\n```bash\n# scripts/cert-management/generate-certs.sh\n#!/bin/bash\n\n# Generate self-signed certificate for development\ngenerate_dev_cert() {\n    openssl req -x509 -newkey rsa:4096 -keyout dev-key.pem -out dev-cert.pem \\\n        -days 365 -nodes -subj \"/CN=PDFExtract Development\"\n}\n\n# Convert Apple certificate for GitHub Actions\nprepare_apple_cert() {\n    local p12_file=\"$1\"\n    base64 < \"$p12_file\" > apple-cert-base64.txt\n    echo \"Add contents of apple-cert-base64.txt to APPLE_CERT_BASE64 secret\"\n}\n\n# Convert Windows certificate\nprepare_windows_cert() {\n    local pfx_file=\"$1\"\n    base64 -w 0 < \"$pfx_file\" > windows-cert-base64.txt\n    echo \"Add contents of windows-cert-base64.txt to WINDOWS_CERT_BASE64 secret\"\n}\n```\n\nImplement signing verification:\n\n```go\n// internal/signing/verify.go\npackage signing\n\nimport (\n    \"crypto/x509\"\n    \"encoding/pem\"\n    \"fmt\"\n    \"os/exec\"\n    \"runtime\"\n)\n\ntype SignatureVerifier struct {\n    trustedCerts []*x509.Certificate\n}\n\nfunc (sv *SignatureVerifier) VerifyBinary(path string) error {\n    switch runtime.GOOS {\n    case \"darwin\":\n        return sv.verifyMacOS(path)\n    case \"windows\":\n        return sv.verifyWindows(path)\n    case \"linux\":\n        return sv.verifyLinux(path)\n    default:\n        return fmt.Errorf(\"unsupported platform: %s\", runtime.GOOS)\n    }\n}\n\nfunc (sv *SignatureVerifier) verifyMacOS(path string) error {\n    cmd := exec.Command(\"codesign\", \"--verify\", \"--deep\", \"--strict\", path)\n    output, err := cmd.CombinedOutput()\n    if err != nil {\n        return fmt.Errorf(\"codesign verification failed: %s\", output)\n    }\n    \n    // Check notarization status\n    cmd = exec.Command(\"spctl\", \"-a\", \"-v\", path)\n    output, err = cmd.CombinedOutput()\n    if err != nil {\n        return fmt.Errorf(\"notarization check failed: %s\", output)\n    }\n    return nil\n}\n\nfunc (sv *SignatureVerifier) verifyWindows(path string) error {\n    cmd := exec.Command(\"signtool\", \"verify\", \"/pa\", \"/v\", path)\n    output, err := cmd.CombinedOutput()\n    if err != nil {\n        return fmt.Errorf(\"signtool verification failed: %s\", output)\n    }\n    return nil\n}\n\nfunc (sv *SignatureVerifier) verifyLinux(path string) error {\n    // Verify GPG signature\n    sigPath := path + \".asc\"\n    cmd := exec.Command(\"gpg\", \"--verify\", sigPath, path)\n    output, err := cmd.CombinedOutput()\n    if err != nil {\n        return fmt.Errorf(\"GPG verification failed: %s\", output)\n    }\n    return nil\n}\n```\n\nCreate entitlements for macOS:\n\n```xml\n<!-- entitlements.plist -->\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>com.apple.security.cs.allow-unsigned-executable-memory</key>\n    <true/>\n    <key>com.apple.security.cs.disable-library-validation</key>\n    <true/>\n</dict>\n</plist>\n```\n\nDocumentation for certificate setup:\n\n```markdown\n# Code Signing Setup Guide\n\n## Prerequisites\n1. Apple Developer Account (for macOS)\n2. Windows Code Signing Certificate\n3. GPG Key (for Linux)\n\n## GitHub Actions Secrets Required\n\n### macOS\n- `APPLE_CERT_BASE64`: Base64 encoded .p12 certificate\n- `APPLE_CERT_PASSWORD`: Certificate password\n- `APPLE_DEVELOPER_ID`: Developer ID Application certificate name\n- `APPLE_ID`: Apple ID for notarization\n- `APPLE_APP_PASSWORD`: App-specific password\n\n### Windows\n- `WINDOWS_CERT_BASE64`: Base64 encoded .pfx certificate\n- `WINDOWS_CERT_PASSWORD`: Certificate password\n\n### Linux\n- `GPG_PRIVATE_KEY`: ASCII armored GPG private key\n- `GPG_PASSPHRASE`: GPG key passphrase\n\n## Certificate Generation Commands\n\n### macOS Development Certificate\n```bash\nsecurity create-keychain -p password build.keychain\nsecurity default-keychain -s build.keychain\nsecurity unlock-keychain -p password build.keychain\n```\n\n### Windows Self-Signed Certificate (Development)\n```powershell\nNew-SelfSignedCertificate -Type CodeSigningCert -Subject \"CN=PDFExtract Dev\" -KeyExportPolicy Exportable -CertStoreLocation Cert:\\CurrentUser\\My\n```\n\n### Linux GPG Key\n```bash\ngpg --full-generate-key\ngpg --armor --export-secret-keys YOUR_KEY_ID > private.asc\n```\n```",
        "testStrategy": "Comprehensive testing strategy for code signing implementation:\n\n1. **Certificate Management Tests**:\n   - Test certificate import/export scripts with dummy certificates\n   - Verify base64 encoding/decoding for all certificate types\n   - Test keychain creation and certificate import on macOS CI\n   - Verify certificate installation on Windows CI\n   - Test GPG key import on Linux CI\n\n2. **Signing Process Tests**:\n   - Create test binaries for each platform\n   - Test signing workflow locally with development certificates\n   - Verify signed binaries can be executed without security warnings\n   - Test notarization workflow on macOS (may require real Apple Developer account)\n   - Verify Windows Authenticode signatures with signtool verify\n   - Test GPG signature creation and verification on Linux\n\n3. **GitHub Actions Integration Tests**:\n   - Create test workflow that runs on push to test branch\n   - Verify secrets are properly accessed and decoded\n   - Test signing steps with self-signed certificates in CI\n   - Verify artifact upload includes signed binaries\n   - Test failure scenarios (missing secrets, invalid certificates)\n\n4. **Verification Tests**:\n   - Implement automated verification for each platform\n   - Test SignatureVerifier.VerifyBinary() with signed and unsigned binaries\n   - Verify error handling for tampered binaries\n   - Test cross-platform verification (e.g., verify Windows binary on Linux)\n\n5. **End-to-End Release Tests**:\n   - Create test release tag to trigger full workflow\n   - Download and test signed binaries on each platform\n   - Verify macOS Gatekeeper acceptance\n   - Test Windows SmartScreen behavior\n   - Verify GPG signature with public key\n\n6. **Security Tests**:\n   - Ensure certificates are not exposed in logs\n   - Verify temporary files are cleaned up\n   - Test certificate rotation procedures\n   - Verify signing timestamps for long-term validity",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up Certificate Management Scripts",
            "description": "Create scripts to manage and convert certificates for macOS, Windows, and Linux platforms.",
            "dependencies": [],
            "details": "Implement scripts to generate development certificates and convert them to base64 for GitHub Actions.",
            "status": "done",
            "testStrategy": "Run the scripts to ensure certificates are generated and converted correctly."
          },
          {
            "id": 2,
            "title": "Configure GitHub Actions for Code Signing",
            "description": "Set up GitHub Actions workflows to automate code signing for macOS, Windows, and Linux binaries.",
            "dependencies": [
              1
            ],
            "details": "Implement workflows in .github/workflows/release.yml to handle code signing for each platform.",
            "status": "done",
            "testStrategy": "Trigger a release workflow and verify that binaries are signed correctly."
          },
          {
            "id": 3,
            "title": "Implement Signing Verification",
            "description": "Develop a verification system to ensure that signed binaries are valid and trusted.",
            "dependencies": [
              2
            ],
            "details": "Create a Go module to verify signatures on macOS, Windows, and Linux binaries.",
            "status": "done",
            "testStrategy": "Run verification tests on signed binaries to ensure they pass signature checks."
          },
          {
            "id": 4,
            "title": "Create macOS Entitlements",
            "description": "Define entitlements for macOS binaries to ensure proper execution and security compliance.",
            "dependencies": [
              2
            ],
            "details": "Develop an entitlements.plist file with necessary permissions for macOS applications.",
            "status": "done",
            "testStrategy": "Test the signed macOS binary to ensure it runs with the specified entitlements."
          },
          {
            "id": 5,
            "title": "Document Code Signing Setup",
            "description": "Create comprehensive documentation for setting up and managing code signing across platforms.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Write a guide detailing prerequisites, setup steps, and GitHub Actions secrets required for code signing.",
            "status": "done",
            "testStrategy": "Review the documentation for completeness and accuracy, ensuring it covers all necessary steps."
          }
        ]
      },
      {
        "id": 17,
        "title": "Fix GitHub Actions Release Workflow for Tag-Based Releases",
        "description": "Update the GitHub Actions release workflow to properly handle tag-triggered releases by replacing existing release information, automatically generating release notes from commit history between tags, and implementing proper draft/pre-release state management.",
        "details": "Implement comprehensive fixes to the GitHub Actions release workflow to handle tag-based releases properly:\n\n```yaml\n# .github/workflows/release.yml\nname: Release\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  create-release:\n    runs-on: ubuntu-latest\n    outputs:\n      release_id: ${{ steps.create_release.outputs.id }}\n      upload_url: ${{ steps.create_release.outputs.upload_url }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0  # Full history for changelog generation\n\n      - name: Get previous tag\n        id: prev_tag\n        run: |\n          CURRENT_TAG=${GITHUB_REF#refs/tags/}\n          PREVIOUS_TAG=$(git describe --tags --abbrev=0 $CURRENT_TAG^ 2>/dev/null || echo \"\")\n          echo \"current_tag=$CURRENT_TAG\" >> $GITHUB_OUTPUT\n          echo \"previous_tag=$PREVIOUS_TAG\" >> $GITHUB_OUTPUT\n\n      - name: Generate release notes\n        id: release_notes\n        run: |\n          CURRENT_TAG=${{ steps.prev_tag.outputs.current_tag }}\n          PREVIOUS_TAG=${{ steps.prev_tag.outputs.previous_tag }}\n          \n          # Generate changelog from commits\n          if [ -z \"$PREVIOUS_TAG\" ]; then\n            CHANGELOG=$(git log --pretty=format:\"- %s (%h)\" --reverse)\n          else\n            CHANGELOG=$(git log --pretty=format:\"- %s (%h)\" --reverse ${PREVIOUS_TAG}..${CURRENT_TAG})\n          fi\n          \n          # Group commits by type\n          FEATURES=$(echo \"$CHANGELOG\" | grep -E \"^- (feat|feature):\" || true)\n          FIXES=$(echo \"$CHANGELOG\" | grep -E \"^- (fix|bugfix):\" || true)\n          DOCS=$(echo \"$CHANGELOG\" | grep -E \"^- (docs|documentation):\" || true)\n          OTHER=$(echo \"$CHANGELOG\" | grep -vE \"^- (feat|feature|fix|bugfix|docs|documentation):\" || true)\n          \n          # Build release notes\n          NOTES=\"## What's Changed\"\n          \n          if [ -n \"$FEATURES\" ]; then\n            NOTES=\"$NOTES\\n\\n###  Features\\n$FEATURES\"\n          fi\n          \n          if [ -n \"$FIXES\" ]; then\n            NOTES=\"$NOTES\\n\\n###  Bug Fixes\\n$FIXES\"\n          fi\n          \n          if [ -n \"$DOCS\" ]; then\n            NOTES=\"$NOTES\\n\\n###  Documentation\\n$DOCS\"\n          fi\n          \n          if [ -n \"$OTHER\" ]; then\n            NOTES=\"$NOTES\\n\\n###  Other Changes\\n$OTHER\"\n          fi\n          \n          # Add comparison link\n          if [ -n \"$PREVIOUS_TAG\" ]; then\n            NOTES=\"$NOTES\\n\\n**Full Changelog**: https://github.com/${{ github.repository }}/compare/${PREVIOUS_TAG}...${CURRENT_TAG}\"\n          fi\n          \n          # Save to file to handle multiline content\n          echo -e \"$NOTES\" > release_notes.md\n          echo \"notes_file=release_notes.md\" >> $GITHUB_OUTPUT\n\n      - name: Check if release exists\n        id: check_release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          TAG=${{ steps.prev_tag.outputs.current_tag }}\n          RELEASE_ID=$(gh api repos/${{ github.repository }}/releases/tags/$TAG --jq '.id' 2>/dev/null || echo \"\")\n          echo \"release_id=$RELEASE_ID\" >> $GITHUB_OUTPUT\n          echo \"exists=$([[ -n \"$RELEASE_ID\" ]] && echo \"true\" || echo \"false\")\" >> $GITHUB_OUTPUT\n\n      - name: Delete existing release\n        if: steps.check_release.outputs.exists == 'true'\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          gh api -X DELETE repos/${{ github.repository }}/releases/${{ steps.check_release.outputs.release_id }}\n          echo \"Deleted existing release for tag ${{ steps.prev_tag.outputs.current_tag }}\"\n\n      - name: Determine release type\n        id: release_type\n        run: |\n          TAG=${{ steps.prev_tag.outputs.current_tag }}\n          \n          # Check if pre-release (contains alpha, beta, rc, etc.)\n          if [[ \"$TAG\" =~ -(alpha|beta|rc|pre|preview|dev)\\. ]]; then\n            echo \"prerelease=true\" >> $GITHUB_OUTPUT\n            echo \"draft=false\" >> $GITHUB_OUTPUT\n          # Check if draft (contains draft or ends with -draft)\n          elif [[ \"$TAG\" =~ -draft$ ]] || [[ \"$TAG\" =~ -draft\\. ]]; then\n            echo \"prerelease=false\" >> $GITHUB_OUTPUT\n            echo \"draft=true\" >> $GITHUB_OUTPUT\n          else\n            echo \"prerelease=false\" >> $GITHUB_OUTPUT\n            echo \"draft=false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Create release\n        id: create_release\n        uses: actions/create-release@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ steps.prev_tag.outputs.current_tag }}\n          release_name: Release ${{ steps.prev_tag.outputs.current_tag }}\n          body_path: ${{ steps.release_notes.outputs.notes_file }}\n          draft: ${{ steps.release_type.outputs.draft }}\n          prerelease: ${{ steps.release_type.outputs.prerelease }}\n\n  build-and-upload:\n    needs: create-release\n    strategy:\n      matrix:\n        include:\n          - os: ubuntu-latest\n            asset_name: app-linux-amd64\n          - os: macos-latest\n            asset_name: app-darwin-amd64\n          - os: windows-latest\n            asset_name: app-windows-amd64.exe\n    runs-on: ${{ matrix.os }}\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Build\n        run: |\n          # Build commands here\n          echo \"Building for ${{ matrix.os }}\"\n          \n      - name: Upload Release Asset\n        uses: actions/upload-release-asset@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ needs.create-release.outputs.upload_url }}\n          asset_path: ./build/${{ matrix.asset_name }}\n          asset_name: ${{ matrix.asset_name }}\n          asset_content_type: application/octet-stream\n```\n\nAdditional considerations for the implementation:\n\n1. **Release Notes Generation Script** (optional standalone script):\n```bash\n#!/bin/bash\n# scripts/generate-release-notes.sh\n\nCURRENT_TAG=$1\nPREVIOUS_TAG=$2\nOUTPUT_FORMAT=${3:-markdown}\n\ngenerate_conventional_changelog() {\n    local from=$1\n    local to=$2\n    \n    # Define commit type mappings\n    declare -A type_headers=(\n        [\"feat\"]=\" Features\"\n        [\"fix\"]=\" Bug Fixes\"\n        [\"docs\"]=\" Documentation\"\n        [\"style\"]=\" Styles\"\n        [\"refactor\"]=\" Code Refactoring\"\n        [\"perf\"]=\" Performance Improvements\"\n        [\"test\"]=\" Tests\"\n        [\"build\"]=\" Build System\"\n        [\"ci\"]=\" Continuous Integration\"\n        [\"chore\"]=\" Chores\"\n        [\"revert\"]=\" Reverts\"\n    )\n    \n    # Extract and group commits\n    for type in \"${!type_headers[@]}\"; do\n        commits=$(git log --pretty=format:\"- %s (%h)\" --grep=\"^${type}:\" ${from}..${to})\n        if [ -n \"$commits\" ]; then\n            echo \"### ${type_headers[$type]}\"\n            echo \"$commits\"\n            echo \"\"\n        fi\n    done\n}\n```\n\n2. **GitHub API Integration for Advanced Features**:\n```yaml\n- name: Update release with additional metadata\n  env:\n    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n  run: |\n    # Add custom fields to release\n    gh api -X PATCH repos/${{ github.repository }}/releases/${{ steps.create_release.outputs.id }} \\\n      --field discussion_category_name=\"Releases\" \\\n      --field generate_release_notes=false\n```\n\n3. **Error Handling and Retry Logic**:\n```yaml\n- name: Create release with retry\n  uses: nick-invision/retry@v2\n  with:\n    timeout_minutes: 5\n    max_attempts: 3\n    retry_on: error\n    command: |\n      gh release create ${{ steps.prev_tag.outputs.current_tag }} \\\n        --title \"Release ${{ steps.prev_tag.outputs.current_tag }}\" \\\n        --notes-file release_notes.md \\\n        ${{ steps.release_type.outputs.draft == 'true' && '--draft' || '' }} \\\n        ${{ steps.release_type.outputs.prerelease == 'true' && '--prerelease' || '' }}\n```",
        "testStrategy": "Comprehensive testing strategy for the GitHub Actions release workflow:\n\n1. **Tag Detection and Parsing Tests**:\n   - Test with various tag formats: `v1.0.0`, `v2.1.0-beta.1`, `v3.0.0-rc.1`, `v1.0.0-draft`\n   - Verify correct detection of current and previous tags\n   - Test edge cases: first release (no previous tag), non-sequential tags\n   - Validate tag pattern matching for triggering workflow\n\n2. **Release Notes Generation Tests**:\n   - Create test repository with conventional commits between tags\n   - Verify correct grouping of commits by type (feat, fix, docs, etc.)\n   - Test with empty commit ranges and single commit releases\n   - Validate markdown formatting and special character escaping\n   - Test commit message parsing with various formats\n\n3. **Release Management Tests**:\n   - Test detection of existing releases for a tag\n   - Verify successful deletion of existing releases before recreation\n   - Test API error handling when release doesn't exist\n   - Validate release creation with correct metadata\n\n4. **Draft/Pre-release Logic Tests**:\n   - Test tags with pre-release identifiers: `-alpha`, `-beta`, `-rc`, `-pre`\n   - Verify draft detection for tags ending with `-draft`\n   - Test standard release tags create non-draft, non-prerelease\n   - Validate boolean flag propagation to release creation\n\n5. **Integration Tests**:\n   - Create test workflow that triggers on push to test tags\n   - Verify complete workflow execution from tag push to release creation\n   - Test with multiple platform builds uploading to same release\n   - Validate asset upload URLs are correctly passed between jobs\n\n6. **Error Handling Tests**:\n   - Test behavior when GitHub API rate limits are hit\n   - Verify graceful handling of network failures\n   - Test with invalid GitHub tokens\n   - Validate workflow behavior when previous steps fail\n\n7. **Manual Testing Checklist**:\n   - Push a new version tag and verify release is created\n   - Push same tag again and verify old release is replaced\n   - Test with pre-release tag (e.g., `v1.0.0-beta.1`)\n   - Test with draft tag (e.g., `v1.0.0-draft`)\n   - Verify release notes contain commits since last tag\n   - Check that release assets are properly uploaded\n   - Validate release appears correctly in GitHub UI",
        "status": "done",
        "dependencies": [
          16
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Release Workflow to Handle Existing Releases",
            "description": "Modify the GitHub Actions workflow to check for existing releases and delete them if necessary before creating a new release.",
            "dependencies": [],
            "details": "Implement a step in the workflow to check if a release already exists for the current tag and delete it if it does.",
            "status": "done",
            "testStrategy": "Test by creating a release with an existing tag and ensure it is deleted and replaced with a new release."
          },
          {
            "id": 2,
            "title": "Implement Release Notes Generation",
            "description": "Enhance the workflow to automatically generate release notes from commit history between tags.",
            "dependencies": [
              1
            ],
            "details": "Use git log to extract commit messages and categorize them into features, fixes, and other changes for release notes.",
            "status": "done",
            "testStrategy": "Verify that release notes are correctly generated and formatted based on commit messages."
          },
          {
            "id": 3,
            "title": "Add Draft and Pre-release State Management",
            "description": "Implement logic to determine if a release should be a draft or pre-release based on the tag name.",
            "dependencies": [
              2
            ],
            "details": "Use regex to check the tag name for indicators of draft or pre-release status and set the release state accordingly.",
            "status": "done",
            "testStrategy": "Test with various tag names to ensure the correct release state is applied."
          },
          {
            "id": 4,
            "title": "Integrate GitHub API for Metadata Updates",
            "description": "Use the GitHub API to add additional metadata to releases, such as discussion categories.",
            "dependencies": [
              3
            ],
            "details": "Implement a step in the workflow to update the release with additional metadata using the GitHub API.",
            "status": "done",
            "testStrategy": "Check that the release metadata is correctly updated by inspecting the release details on GitHub."
          },
          {
            "id": 5,
            "title": "Implement Error Handling and Retry Logic",
            "description": "Add error handling and retry logic to the release creation process to ensure robustness.",
            "dependencies": [
              4
            ],
            "details": "Use a retry mechanism to handle transient errors during release creation, with configurable timeout and retry attempts.",
            "status": "done",
            "testStrategy": "Simulate errors during release creation and verify that the retry logic successfully handles them."
          }
        ]
      },
      {
        "id": 18,
        "title": "Create Automated Release Preparation System",
        "description": "Design and implement a comprehensive release automation system that handles version tagging, changelog generation from commit history, release note compilation, and orchestrates the complete release process including pre-release checks and post-release notifications.",
        "details": "Implement a complete release preparation system with multiple components:\n\n```go\n// internal/release/manager.go\npackage release\n\ntype ReleaseManager struct {\n    git         *GitClient\n    changelog   *ChangelogGenerator\n    versioning  *VersionManager\n    validator   *ReleaseValidator\n    notifier    *ReleaseNotifier\n}\n\nfunc (rm *ReleaseManager) PrepareRelease(version string, releaseType ReleaseType) (*Release, error) {\n    // 1. Validate version format\n    if err := rm.versioning.ValidateVersion(version); err != nil {\n        return nil, fmt.Errorf(\"invalid version: %w\", err)\n    }\n    \n    // 2. Run pre-release checks\n    if err := rm.validator.RunPreReleaseChecks(); err != nil {\n        return nil, fmt.Errorf(\"pre-release checks failed: %w\", err)\n    }\n    \n    // 3. Generate changelog\n    changelog, err := rm.changelog.Generate(version)\n    if err != nil {\n        return nil, fmt.Errorf(\"changelog generation failed: %w\", err)\n    }\n    \n    // 4. Create release object\n    release := &Release{\n        Version:     version,\n        Type:        releaseType,\n        Changelog:   changelog,\n        CreatedAt:   time.Now(),\n    }\n    \n    return release, nil\n}\n\n// internal/release/changelog.go\ntype ChangelogGenerator struct {\n    git    *GitClient\n    parser *CommitParser\n}\n\nfunc (cg *ChangelogGenerator) Generate(targetVersion string) (*Changelog, error) {\n    // Get previous version tag\n    prevTag, err := cg.git.GetPreviousTag(targetVersion)\n    if err != nil {\n        prevTag = \"\" // First release\n    }\n    \n    // Get commits between tags\n    commits, err := cg.git.GetCommitsBetween(prevTag, \"HEAD\")\n    if err != nil {\n        return nil, err\n    }\n    \n    // Parse and categorize commits\n    changelog := &Changelog{\n        Version:  targetVersion,\n        Date:     time.Now(),\n        Sections: make(map[string][]ChangeEntry),\n    }\n    \n    for _, commit := range commits {\n        entry := cg.parser.ParseCommit(commit)\n        if entry != nil {\n            changelog.AddEntry(entry)\n        }\n    }\n    \n    return changelog, nil\n}\n\n// internal/release/version.go\ntype VersionManager struct {\n    strategy VersionStrategy\n}\n\nfunc (vm *VersionManager) NextVersion(currentVersion string, bumpType BumpType) (string, error) {\n    current, err := semver.Parse(currentVersion)\n    if err != nil {\n        return \"\", err\n    }\n    \n    switch bumpType {\n    case BumpMajor:\n        return fmt.Sprintf(\"v%d.0.0\", current.Major+1), nil\n    case BumpMinor:\n        return fmt.Sprintf(\"v%d.%d.0\", current.Major, current.Minor+1), nil\n    case BumpPatch:\n        return fmt.Sprintf(\"v%d.%d.%d\", current.Major, current.Minor, current.Patch+1), nil\n    }\n    \n    return \"\", fmt.Errorf(\"unknown bump type: %v\", bumpType)\n}\n\n// internal/release/validator.go\ntype ReleaseValidator struct {\n    checks []ReleaseCheck\n}\n\nfunc (rv *ReleaseValidator) RunPreReleaseChecks() error {\n    for _, check := range rv.checks {\n        if err := check.Run(); err != nil {\n            return fmt.Errorf(\"check '%s' failed: %w\", check.Name(), err)\n        }\n    }\n    return nil\n}\n\n// Implement various checks\ntype TestsPassCheck struct{}\nfunc (t *TestsPassCheck) Run() error {\n    // Run go test ./...\n    cmd := exec.Command(\"go\", \"test\", \"./...\")\n    if err := cmd.Run(); err != nil {\n        return fmt.Errorf(\"tests failed\")\n    }\n    return nil\n}\n\ntype BuildCheck struct{}\nfunc (b *BuildCheck) Run() error {\n    // Verify build succeeds\n    cmd := exec.Command(\"go\", \"build\", \"./...\")\n    return cmd.Run()\n}\n\n// cmd/release/main.go\npackage main\n\nimport (\n    \"github.com/spf13/cobra\"\n)\n\nfunc main() {\n    rootCmd := &cobra.Command{\n        Use:   \"release\",\n        Short: \"Automated release preparation tool\",\n    }\n    \n    prepareCmd := &cobra.Command{\n        Use:   \"prepare [version]\",\n        Short: \"Prepare a new release\",\n        RunE: func(cmd *cobra.Command, args []string) error {\n            manager := release.NewManager()\n            \n            version := args[0]\n            releaseType, _ := cmd.Flags().GetString(\"type\")\n            \n            rel, err := manager.PrepareRelease(version, releaseType)\n            if err != nil {\n                return err\n            }\n            \n            // Output release information\n            fmt.Printf(\"Release %s prepared successfully\\n\", rel.Version)\n            fmt.Printf(\"Changelog:\\n%s\\n\", rel.Changelog.Format())\n            \n            return nil\n        },\n    }\n    \n    rootCmd.AddCommand(prepareCmd)\n    rootCmd.Execute()\n}\n\n// .github/workflows/release-automation.yml\nname: Automated Release Process\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'Release version (e.g., v1.2.3)'\n        required: true\n      release_type:\n        description: 'Release type'\n        type: choice\n        options:\n          - stable\n          - beta\n          - rc\n\njobs:\n  prepare-release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          \n      - name: Setup Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: '1.21'\n          \n      - name: Run Release Preparation\n        run: |\n          go run cmd/release/main.go prepare ${{ github.event.inputs.version }} \\\n            --type ${{ github.event.inputs.release_type }}\n            \n      - name: Create Release PR\n        uses: peter-evans/create-pull-request@v5\n        with:\n          title: \"Release ${{ github.event.inputs.version }}\"\n          body: |\n            Automated release preparation for version ${{ github.event.inputs.version }}\n            \n            ## Checklist\n            - [ ] Tests passing\n            - [ ] Changelog reviewed\n            - [ ] Version bumped\n            - [ ] Documentation updated\n          branch: release/${{ github.event.inputs.version }}\n\n// internal/release/templates/changelog.tmpl\n# Changelog\n\n## [{{ .Version }}] - {{ .Date.Format \"2006-01-02\" }}\n\n{{ range $section, $entries := .Sections }}\n### {{ $section }}\n{{ range $entries }}\n- {{ .Description }} ({{ .CommitHash }})\n{{ end }}\n{{ end }}\n\n## Previous Releases\n{{ .PreviousContent }}\n\n// pkg/models/release.go\ntype Release struct {\n    Version     string\n    Type        ReleaseType\n    Changelog   *Changelog\n    Assets      []ReleaseAsset\n    CreatedAt   time.Time\n    PublishedAt *time.Time\n}\n\ntype Changelog struct {\n    Version  string\n    Date     time.Time\n    Sections map[string][]ChangeEntry\n}\n\ntype ChangeEntry struct {\n    Type        string // feat, fix, docs, etc.\n    Scope       string\n    Description string\n    CommitHash  string\n    Author      string\n    Breaking    bool\n}",
        "testStrategy": "Comprehensive testing strategy for the release preparation system:\n\n1. **Version Management Tests**:\n   - Test semantic version parsing and validation\n   - Verify version bumping logic (major, minor, patch)\n   - Test pre-release version handling (beta, rc)\n   - Validate version format compliance\n\n2. **Changelog Generation Tests**:\n   - Mock git repository with various commit patterns\n   - Test conventional commit parsing (feat:, fix:, docs:, etc.)\n   - Verify commit categorization and grouping\n   - Test changelog formatting with different templates\n   - Handle edge cases: first release, no commits, merge commits\n\n3. **Pre-release Validation Tests**:\n   - Mock successful and failing test runs\n   - Verify build check execution\n   - Test custom validation rules\n   - Ensure proper error reporting and aggregation\n\n4. **Integration Tests**:\n   - Test complete release preparation flow\n   - Verify file generation (CHANGELOG.md, VERSION)\n   - Test git operations (tag creation, commit)\n   - Validate GitHub Actions workflow execution\n\n5. **CLI Tests**:\n   - Test command parsing and validation\n   - Verify output formatting\n   - Test interactive mode prompts\n   - Validate error handling and help text\n\n6. **End-to-End Tests**:\n   - Create test repository with sample commits\n   - Run full release preparation\n   - Verify all artifacts are created correctly\n   - Test rollback on failure",
        "status": "done",
        "dependencies": [
          16,
          17
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Version Validation and Management",
            "description": "Develop the version validation and management component to ensure correct version formats and calculate the next version based on the bump type.",
            "dependencies": [],
            "details": "Create methods to validate version formats and determine the next version using semantic versioning rules.",
            "status": "done",
            "testStrategy": "Write unit tests to validate version formats and ensure correct version bumping."
          },
          {
            "id": 2,
            "title": "Develop Pre-Release Validation Checks",
            "description": "Implement pre-release validation checks to ensure code quality and build integrity before proceeding with the release.",
            "dependencies": [],
            "details": "Create checks such as running tests and verifying build success to ensure the codebase is ready for release.",
            "status": "done",
            "testStrategy": "Simulate various scenarios where checks fail and pass to ensure robustness."
          },
          {
            "id": 3,
            "title": "Create Changelog Generation System",
            "description": "Design and implement a system to generate changelogs from commit history, categorizing changes appropriately.",
            "dependencies": [
              1
            ],
            "details": "Use commit history to generate a structured changelog, categorizing changes by type and scope.",
            "status": "done",
            "testStrategy": "Test with different commit histories to ensure accurate and comprehensive changelog generation."
          },
          {
            "id": 4,
            "title": "Integrate Release Preparation Workflow",
            "description": "Integrate all components into a cohesive release preparation workflow that automates the release process.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Combine version management, validation checks, and changelog generation into a single automated workflow.",
            "status": "done",
            "testStrategy": "Perform end-to-end testing of the release preparation process to ensure all components work together seamlessly."
          },
          {
            "id": 5,
            "title": "Implement Post-Release Notification System",
            "description": "Develop a notification system to inform stakeholders of release completion and provide release details.",
            "dependencies": [
              4
            ],
            "details": "Create a notification mechanism to send release details and changelogs to relevant stakeholders after release completion.",
            "status": "done",
            "testStrategy": "Test notifications with various stakeholders to ensure timely and accurate information delivery."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-06-20T03:09:52.219Z",
      "updated": "2025-06-20T07:10:26.899Z",
      "description": "Tasks for master context"
    }
  }
}